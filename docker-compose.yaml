services:
  controller-1:
    image: apache/kafka:latest
    container_name: controller-1
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: controller
      KAFKA_LISTENERS: CONTROLLER://:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093,3@controller-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks:
      - kafka_network
  controller-2:
    image: apache/kafka:latest
    container_name: controller-2
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: controller
      KAFKA_LISTENERS: CONTROLLER://:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093,3@controller-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks:
      - kafka_network
  controller-3:
    image: apache/kafka:latest
    container_name: controller-3
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: controller
      KAFKA_LISTENERS: CONTROLLER://:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093,3@controller-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks:
      - kafka_network
  broker-1:
    image: apache/kafka:latest
    container_name: broker-1
    ports:
      - "19092:9092"
    environment:
      KAFKA_NODE_ID: 4
      KAFKA_PROCESS_ROLES: broker
      KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-1:19092,PLAINTEXT_HOST://localhost:19092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093,3@controller-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Custom
      KAFKA_LOG_DIRS: /var/lib/kafka/logs  # Custom log directory
      KAFKA_LOG_RETENTION_HOURS: 168  # Retain logs for a week
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB log segment size
      KAFKA_LOG_CLEANUP_POLICY: delete  # Delete old log segments
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 1000  # Flush log after 10000messages
      KAFKA_LOG_FLUSH_INTERVAL_MS: 1000  # Flush log every 1 second
      KAFKA_CONSUMER_FETCH_MAX_WAIT_MS: 500  # Max fetch wait time for consumers
      KAFKA_REPLICATION_FACTOR: 3  # Replication factor for fault tolerance
      KAFKA_NUM_PARTITIONS: 6  # Number of partitions (adjust based on the expected workload)
      # Logging Level Configuration
      KAFKA_LOG4J_LOGGER: "kafka=DEBUG, kafkaAppender"
    configs:
      - source: log4j_config
        target: /opt/kafka/config/log4j.properties
    deploy:
      resources:
        limits:
          memory: 2G  # Limit memory usage to 4GB
          cpus: '1.0'  # Limit CPU usage to 2 cores
        reservations:
          memory: 1G  # Reserve 2GB memory
          cpus: '1.0'  # Reserve 1 CPU core
    depends_on:
      - controller-1
      - controller-2
      - controller-3
    networks:
      - kafka_network

  broker-2:
    image: apache/kafka:latest
    container_name: broker-2
    ports:
      - "29092:9092"
    environment:
      KAFKA_NODE_ID: 5
      KAFKA_PROCESS_ROLES: broker
      KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-2:19092,PLAINTEXT_HOST://localhost:29092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093,3@controller-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Custom
      KAFKA_LOG_DIRS: /var/lib/kafka/logs  # Custom log directory
      KAFKA_LOG_RETENTION_HOURS: 168  # Retain logs for a week
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB log segment size
      KAFKA_LOG_CLEANUP_POLICY: delete  # Delete old log segments
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 1000  # Flush log after 10000messages
      KAFKA_LOG_FLUSH_INTERVAL_MS: 1000  # Flush log every 1 second
      KAFKA_CONSUMER_FETCH_MAX_WAIT_MS: 500  # Max fetch wait time for consumers
      KAFKA_REPLICATION_FACTOR: 3  # Replication factor for fault tolerance
      KAFKA_NUM_PARTITIONS: 6  # Number of partitions (adjust based on the expected workload)
      # Logging Level Configuration
      KAFKA_LOG4J_LOGGER: "kafka=DEBUG, kafkaAppender"
    configs:
      - source: log4j_config
        target: /opt/kafka/config/log4j.properties
    deploy:
      resources:
        limits:
          memory: 2G  # Limit memory usage to 4GB
          cpus: '1.0'  # Limit CPU usage to 2 cores
        reservations:
          memory: 1G  # Reserve 2GB memory
          cpus: '1.0'  # Reserve 1 CPU core
    depends_on:
      - controller-1
      - controller-2
      - controller-3
    networks:
      - kafka_network

  broker-3:
    image: apache/kafka:latest
    container_name: broker-3
    ports:
      - "39092:9092"
    environment:
      KAFKA_NODE_ID: 6
      KAFKA_PROCESS_ROLES: broker
      KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-3:19092,PLAINTEXT_HOST://localhost:39092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093,3@controller-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Custom
      KAFKA_LOG_DIRS: /var/lib/kafka/logs  # Custom log directory
      KAFKA_LOG_RETENTION_HOURS: 168  # Retain logs for a week
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB log segment size
      KAFKA_LOG_CLEANUP_POLICY: delete  # Delete old log segments
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 1000  # Flush log after 10000messages
      KAFKA_LOG_FLUSH_INTERVAL_MS: 1000  # Flush log every 1 second
      KAFKA_CONSUMER_FETCH_MAX_WAIT_MS: 500  # Max fetch wait time for consumers
      KAFKA_REPLICATION_FACTOR: 3  # Replication factor for fault tolerance
      KAFKA_NUM_PARTITIONS: 6  # Number of partitions (adjust based on the expected workload)
      # Logging Level Configuration
      KAFKA_LOG4J_LOGGER: "kafka=DEBUG, kafkaAppender"
    configs:
      - source: log4j_config
        target: /opt/kafka/config/log4j.properties
    deploy:
      resources:
        limits:
          memory: 2G  # Limit memory usage to 4GB
          cpus: '1.0'  # Limit CPU usage to 2 cores
        reservations:
          memory: 1G  # Reserve 2GB memory
          cpus: '1.0'  # Reserve 1 CPU core
    depends_on:
      - controller-1
      - controller-2
      - controller-3
    networks:
      - kafka_network


  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    networks:
      - kafka_network
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: "admin"
    depends_on:
      - prometheus
    networks:
      - kafka_network

  # After
  kafka-exporter:
    image: danielqsj/kafka-exporter
    container_name: kafka-exporter-1
    ports:
      - "1308:9308"
    command:
      - --kafka.server=broker-1:19092
      - --kafka.server=broker-1:29092
      - --kafka.server=broker-1:39092
      - --log.level=debug
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    networks:
      - kafka_network


networks:
  kafka_network:
    driver: bridge
configs:
  log4j_config:
    content: |
      log4j.rootLogger=INFO, stdout, file
      log4j.appender.stdout=org.apache.log4j.ConsoleAppender
      log4j.appender.stdout.Target=System.out
      log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
      log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} - %m%n
      log4j.appender.file=org.apache.log4j.RollingFileAppender
      log4j.appender.file.File=/var/log/kafka/server.log
      log4j.appender.file.MaxFileSize=100MB
      log4j.appender.file.MaxBackupIndex=10
      log4j.appender.file.layout=org.apache.log4j.PatternLayout
      log4j.appender.file.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} - %m%n
      # Kafka specific loggers
      log4j.logger.kafka=INFO
      log4j.logger.org.apache.zookeeper=INFO
      log4j.logger.org.apache.kafka=INFO